w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- w %*% as.matrix(X.new) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (misclass *  CLASS) # 5 points
}
}
}
perceptron(X,y)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
source('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
hypothesis <- w %*% as.matrix(t(X.new)) # 5 points
source('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
hypothesis <- t(w %*% as.matrix(t(X.new))) # 5 points
# Create a dataset
source('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
source('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
source('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- t(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + c(CLASS, misclass(i,1), misclass(i,2)) # 5 points
}
print(w)
}
}
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- t(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + c(CLASS, misclass[i,1], misclass[i,2]) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- t(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(t(w %*% as.matrix(t(X.new)))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
#w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(t(w %*% as.matrix(t(X.new)))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
#w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (misclass$label.new * misclass$x1 * misclass$x2) # 5 points
}
}
}
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (misclass.label.new * misclass.x1 * misclass.x2) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass.x1 * misclass.x2) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass(x1) * misclass(x2)) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass[,'x1'] * misclass[,'x2']) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass['x1'] * misclass['x2']) # 5 points
}
}
}
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass[,1] * misclass[,2]) # 5 points
}
}
}
perceptron(X,y)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
View(where)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
View(where)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(where)
View(label.new)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
?type.convert
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
typeof(get(misclass))
typeof(misclass)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(X.new)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass,]) # 5 points
}
}
}
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass,]) # 5 points
}
}
}
perceptron(X,y)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass]) # 5 points
}
}
}
perceptron(x,y)
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass]) # 5 points
}
}
}
perceptron(X,y)
set.seed(5)
x1 <- runif(100, -1, 1)
x2 <- runif(100, -1, 1)
X <- data.frame(x1, x2)
# Randomly select two points to create a line going through them, points on one side
# of the line get class label -1, the ones on the other side get class label 1
p1x <- runif(1, -1, 1)
p1y <- runif(1, -1, 1)
p2x <- runif(1, -1, 1)
p2y <- runif(1, -1, 1)
slope <- (p1y-p2y)/(p1x-p2x)
intercept <- p1y - slope * p1x
y <- ifelse((slope*X[,1]+intercept) >= X[,2], -1, 1) # assign class label
# plot the data
data <- cbind(X, y)
plot(data[data$y == -1, 1:2], xlim=c(-1,1), ylim=c(-1,1), col="red")
points(data[data$y == 1, 1:2], col="green")
abline(intercept, slope)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- as.matrix(w + (X.new[misclass,] * CLASS[misclass])) # 5 points
}
}
}
perceptron(X,y)
# Create 100 uniformly distributed points in [-1,1]x[-1,1]
set.seed(5)
x1 <- runif(100, -1, 1)
x2 <- runif(100, -1, 1)
X <- data.frame(x1, x2)
# Randomly select two points to create a line going through them, points on one side
# of the line get class label -1, the ones on the other side get class label 1
p1x <- runif(1, -1, 1)
p1y <- runif(1, -1, 1)
p2x <- runif(1, -1, 1)
p2y <- runif(1, -1, 1)
slope <- (p1y-p2y)/(p1x-p2x)
intercept <- p1y - slope * p1x
y <- ifelse((slope*X[,1]+intercept) >= X[,2], -1, 1) # assign class label
# plot the data
data <- cbind(X, y)
plot(data[data$y == -1, 1:2], xlim=c(-1,1), ylim=c(-1,1), col="red")
points(data[data$y == 1, 1:2], col="green")
abline(intercept, slope)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- as.matrix(w + (X.new[misclass,] * CLASS[misclass])) # 5 points
}
}
}
perceptron(X,y)
library(Matrix)
library(arules)
library(arulesSequences)
library(arules)
library(arulesSequences)
library(permute)
library(tidyr)
library(dplyr)
library(compare)
x <- read_baskets(con = "data2.txt", info = c("sequenceID","eventID","SIZE")) #read file as transaction
#frequentTestData <- cspade(x, parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
#frequentTestData <- as(frequentTestData,"data.frame")
y <- as(x,"data.frame")
#permute the sequences
#run cspade again
#repeat 100 times total
agg <- aggregate(eventID ~ sequenceID:eventID, data = y, c) #aggregera eventIDs till en rad per seqID
#randomisera chars i varje sträng
#?
agg$eventID <- lapply(agg$eventID,sample,replace=F) #verkar funka. randomiserar vector.
agg$eventID <- lapply(agg$eventID,toString) #gör till strängar för att kunna använda separate_rows lättare
#splitta varje eventID i flera rader.
separated <- separate_rows(agg, eventID, sep = ",") #separera eventID till flera rader.
#separate_rows ger fler rader än i y!!! Varför???
setwd("C:/Users/Jennifer/Desktop/DVK/HT-16/Exjobb/Filer för research")
library(arules)
library(arulesSequences)
library(permute)
library(tidyr)
library(dplyr)
library(compare)
x <- read_baskets(con = "data2.txt", info = c("sequenceID","eventID","SIZE")) #read file as transaction
#frequentTestData <- cspade(x, parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
#frequentTestData <- as(frequentTestData,"data.frame")
y <- as(x,"data.frame")
#permute the sequences
#run cspade again
#repeat 100 times total
agg <- aggregate(eventID ~ sequenceID:eventID, data = y, c) #aggregera eventIDs till en rad per seqID
#randomisera chars i varje sträng
#?
agg$eventID <- lapply(agg$eventID,sample,replace=F) #verkar funka. randomiserar vector.
agg$eventID <- lapply(agg$eventID,toString) #gör till strängar för att kunna använda separate_rows lättare
#splitta varje eventID i flera rader.
separated <- separate_rows(agg, eventID, sep = ",") #separera eventID till flera rader.
#separate_rows ger fler rader än i y!!! Varför???
View(y)
View(separated)
View(agg)
?aggregate
aggregate(y.sequenceID, y.eventID, length)
aggregate(y$sequenceID, y$eventID, length)
aggregate(y$sequenceID, length)
aggregate(y$sequenceID, y, length)
y_count <- aggregate(y$sequenceID, y, length)
View(y_count)
y_count <- aggregate(y$sequenceID ~ y$eventID, y, length)
y_count <- aggregate(y$count ~ y$sequenceID, y, length)
y_count <- aggregate(y$eventID ~ y$sequenceID, y, length)
View(y_count)
seperated_count <- aggregate(separated$eventID ~ separated$sequenceID, separated, length)
View(seperated_count)
all.equal()
?all.equal
all.equal(seperated_count, y_count)
all.equal(seperated_count, y_count, use.names= FALSE)
which(seperated_count != y_count, arr.ind=TRUE)
