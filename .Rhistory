label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + c(CLASS, misclass[i,1], misclass[i,2]) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- t(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(t(w %*% as.matrix(t(X.new)))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
#w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
print(w)
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(t(w %*% as.matrix(t(X.new)))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
#w <- w +  c(Y(i), X(i,1), X(i,2)) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (misclass$label.new * misclass$x1 * misclass$x2) # 5 points
}
}
}
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (misclass.label.new * misclass.x1 * misclass.x2) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass.x1 * misclass.x2) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass(x1) * misclass(x2)) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass[,'x1'] * misclass[,'x2']) # 5 points
}
}
}
perceptron(X,y)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass['x1'] * misclass['x2']) # 5 points
}
}
}
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- w + (label.new * misclass[,1] * misclass[,2]) # 5 points
}
}
}
perceptron(X,y)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
View(where)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
View(where)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(where)
View(label.new)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(label.new)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
?type.convert
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
typeof(get(misclass))
typeof(misclass)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
View(X.new)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass,]) # 5 points
}
}
}
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass,]) # 5 points
}
}
}
perceptron(X,y)
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
debugSource('C:/Users/Jennifer/Desktop/DVK/HT-16/DAMI/Ass3/PETERSEN -- assignment 3.r')
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% as.matrix(t(X.new))) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass]) # 5 points
}
}
}
perceptron(x,y)
perceptron(X,y)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
print(typeof(misclass))
# update the weight vector using this randomly selected misclassified point
w <- w + (X.new[misclass,] * CLASS[misclass]) # 5 points
}
}
}
perceptron(X,y)
set.seed(5)
x1 <- runif(100, -1, 1)
x2 <- runif(100, -1, 1)
X <- data.frame(x1, x2)
# Randomly select two points to create a line going through them, points on one side
# of the line get class label -1, the ones on the other side get class label 1
p1x <- runif(1, -1, 1)
p1y <- runif(1, -1, 1)
p2x <- runif(1, -1, 1)
p2y <- runif(1, -1, 1)
slope <- (p1y-p2y)/(p1x-p2x)
intercept <- p1y - slope * p1x
y <- ifelse((slope*X[,1]+intercept) >= X[,2], -1, 1) # assign class label
# plot the data
data <- cbind(X, y)
plot(data[data$y == -1, 1:2], xlim=c(-1,1), ylim=c(-1,1), col="red")
points(data[data$y == 1, 1:2], col="green")
abline(intercept, slope)
# Perceptron learning algorithm
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- as.matrix(w + (X.new[misclass,] * CLASS[misclass])) # 5 points
}
}
}
perceptron(X,y)
# Create 100 uniformly distributed points in [-1,1]x[-1,1]
set.seed(5)
x1 <- runif(100, -1, 1)
x2 <- runif(100, -1, 1)
X <- data.frame(x1, x2)
# Randomly select two points to create a line going through them, points on one side
# of the line get class label -1, the ones on the other side get class label 1
p1x <- runif(1, -1, 1)
p1y <- runif(1, -1, 1)
p2x <- runif(1, -1, 1)
p2y <- runif(1, -1, 1)
slope <- (p1y-p2y)/(p1x-p2x)
intercept <- p1y - slope * p1x
y <- ifelse((slope*X[,1]+intercept) >= X[,2], -1, 1) # assign class label
# plot the data
data <- cbind(X, y)
plot(data[data$y == -1, 1:2], xlim=c(-1,1), ylim=c(-1,1), col="red")
points(data[data$y == 1, 1:2], col="green")
abline(intercept, slope)
perceptron <- function(DATA, CLASS){
X.new <- cbind(1, DATA) # Add X0, which is 1 for all examples
w <- matrix(0,1,3) # Initial weight vector with only 0, note that the first element is w0
while(TRUE){
# use matrix product to calculate the hypothesis. Hint: make sure both parts are matrix
hypothesis <- sign(w %*% t(X.new)) # 5 points
label.new <- ifelse(hypothesis >= 0, 1, -1) # use the sign of hypothesis to decide the class label
if(all(label.new==CLASS)){ # if the new class label from hypothesis is the same with the true class label, then stop the iteration
return(w)
break
}else{ # if the new class label from hypothesis is not the same with the true label, update the weight vector and continue the iteration
where <- label.new == CLASS
misclass <- sample(grep("FALSE", where), 1) # randomly select a misclassified point
# update the weight vector using this randomly selected misclassified point
w <- as.matrix(w + (X.new[misclass,] * CLASS[misclass])) # 5 points
}
}
}
perceptron(X,y)
library(Matrix)
library(arules)
library(arulesSequences)
setwd("C:/Users/Jennifer/Desktop/DVK/HT-16/Exjobb/Filer för research")
library(arules)
library(arulesSequences)
library(permute)
library(tidyr)
library(dplyr)
library(compare)
x <- read_baskets(con = "data2.txt", info = c("sequenceID","eventID","SIZE")) #read file as transaction
#frequentTestData <- cspade(x, parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
#frequentTestData <- as(frequentTestData,"data.frame")
y <- as(x,"data.frame")
#permute the sequences
#run cspade again
#repeat 100 times total
agg <- aggregate(eventID ~ sequenceID:eventID, data = y, c) #aggregera eventIDs till en rad per seqID
#randomisera chars i varje sträng
#?
agg$eventID <- lapply(agg$eventID,sample,replace=F) #verkar funka. randomiserar vector.
agg$eventID <- lapply(agg$eventID,toString) #gör till strängar för att kunna använda separate_rows lättare
#splitta varje eventID i flera rader.
separated <- separate_rows(agg, eventID, sep = ",") #separera eventID till flera rader.
#separate_rows ger fler rader än i y!!! Varför???
seperated_count <- aggregate(separated$eventID ~ separated$sequenceID, separated, length)
y_count <- aggregate(y$eventID ~ y$sequenceID, y, length)
which(seperated_count != y_count, arr.ind=TRUE)
View(agg)
View(y)
agg <- aggregate(eventID ~ sequenceID, data = y, c) #aggregera eventIDs till en rad per seqID
#randomisera chars i varje sträng
#?
agg$eventID <- lapply(agg$eventID,sample,replace=F) #verkar funka. randomiserar vector.
agg$eventID <- lapply(agg$eventID,toString) #gör till strängar för att kunna använda separate_rows lättare
#splitta varje eventID i flera rader.
separated <- separate_rows(agg, eventID, sep = ",") #separera eventID till flera rader.
#separate_rows ger fler rader än i y!!! Varför???
seperated_count <- aggregate(separated$eventID ~ separated$sequenceID, separated, length)
y_count <- aggregate(y$eventID ~ y$sequenceID, y, length)
which(seperated_count != y_count, arr.ind=TRUE)
View(agg)
View(y)
y[11862, 3] = 1
View(y)
agg <- aggregate(eventID ~ sequenceID, data = y, c) #aggregera eventIDs till en rad per seqID
#randomisera chars i varje sträng
#?
agg$eventID <- lapply(agg$eventID,sample,replace=F) #verkar funka. randomiserar vector.
agg$eventID <- lapply(agg$eventID,toString) #gör till strängar för att kunna använda separate_rows lättare
#splitta varje eventID i flera rader.
separated <- separate_rows(agg, eventID, sep = ",") #separera eventID till flera rader.
#separate_rows ger fler rader än i y!!! Varför???
seperated_count <- aggregate(separated$eventID ~ separated$sequenceID, separated, length)
y_count <- aggregate(y$eventID ~ y$sequenceID, y, length)
which(seperated_count != y_count, arr.ind=TRUE)
View(agg)
colnames(y) <- c("items", "oldSeqID", "oldEvent", "size")
mergedData <- cbind(y, separated) #funkar ej då separated av nån anledning har 48 st fler rader nu.
View(mergedData)
mergedData$oldSeqID <- NULL
mergedData$oldEvent <- NULL
View(y)
mergedData[,c(1,3,4,2)]
mergedData <- mergedData[,c(1,3,4,2)]
mergedData[with(mergedData, order("sequenceID", "eventID")), ]
mergedData <- mergedData[with(mergedData, order("sequenceID", "eventID")), ]
View(mergedData)
mergedData <- cbind(y, separated) #funkar ej då separated av nån anledning har 48 st fler rader nu.
mergedData$oldSeqID <- NULL
mergedData$oldEvent <- NULL
mergedData <- mergedData[,c(1,3,4,2)]
View(mergedData)
mergedData[with(mergedData, order(mergedData$sequenceID, mergedData$eventID)), ]
mergedData <- mergedData[with(mergedData, order(mergedData$sequenceID, mergedData$eventID)), ]
View(mergedData)
mergedData <- mergedData[order(mergedData$sequenceID, mergedData$eventID), ]
View(mergedData)
mergedData <- mergedData[order("sequenceID", "eventID"), ]
View(mergedData)
mergedData <- cbind(y, separated) #funkar ej då separated av nån anledning har 48 st fler rader nu.
mergedData$oldSeqID <- NULL
mergedData$oldEvent <- NULL
mergedData <- mergedData[,c(1,3,4,2)]
head(mergedData[order("sequenceID", "eventID"), ])
head(mergedData[, order("sequenceID", "eventID") ])
mergedData<- mergedData[, order("sequenceID", "eventID") ]
mergedData <- cbind(y, separated) #funkar ej då separated av nån anledning har 48 st fler rader nu.
mergedData$oldSeqID <- NULL
mergedData$oldEvent <- NULL
mergedData <- mergedData[,c(1,3,4,2)]
P?order
?order
mergedData <- mergedData[order(mergedData$sequenceID, mergedData$eventID) ,]
View(mergedData)
mergedData <- mergedData[order(mergedData$sequenceID) ,]
View(mergedData)
mergedData <- mergedData[order(mergedData$eventID) ,]
View(mergedData)
mergedData <- mergedData[order(mergedData$sequenceID mergedData$eventID) ,]
mergedData <- mergedData[order(mergedData$sequenceID, mergedData$eventID) ,]
View(mergedData)
mergedData$eventID <- as.numeric(mergedData$eventID)
View(mergedData)
mergedData <- mergedData[order(mergedData$sequenceID, mergedData$eventID) ,]
View(mergedData)
frequent <- cspade(mergedData, parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
x <- read_baskets(mergedData, info = c("sequenceID","eventID","SIZE"))
?read_baskets
write.table(mergedData, "newRandoms.txt", na="", row.names=FALSE, col.names=FALSE)
frequent <- cspade("newRandoms.txt", parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
x <- read_baskets(con = "newRandoms.txt", info = c("sequenceID","eventID","SIZE")) #read file as transaction
View(mergedData)
mergedData <- mergedData[,c(2,3,4,1)]
write.table(mergedData, "newRandoms.txt", na="", row.names=FALSE, col.names=FALSE)
x <- read_baskets(con = "newRandoms.txt", info = c("sequenceID","eventID","SIZE")) #read file as transaction
frequent <- cspade(x, parameter = list(support = 0.01), control = list(verbose = TRUE)) #find frequent
frequent <- as(frequent,"data.frame")
summary(x)
summary(frequent)
View(y)
